import logging
from datetime import datetime
from typing import Optional, Tuple, List

import pandas as pd
import requests
import streamlit as st
from bs4 import BeautifulSoup
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# ==========
# ãƒ­ã‚®ãƒ³ã‚°
# ==========
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ==========
# å®šæ•°
# ==========
LOCATIONS: List[str] = ["æ–°äº•æ¶ˆé˜²ç½²", "é ¸å—æ¶ˆé˜²ç½²", "å¦™é«˜å¸‚å½¹æ‰€ å¦™é«˜æ”¯æ‰€"]

CSV_FILE = "data_urls.csv"
HISTORY_CSV_FILE = "snow_data_history.csv"

HISTORY_REQUIRED_COLS = ["year", "month", "day", "location", "snowfall_cm", "snowdepth_cm"]


# ==========
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ==========
@st.cache_data(ttl=3600)
def load_url_data() -> pd.DataFrame:
    """URLä¸€è¦§CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆåˆ—: å¹´, æœˆ, URL ã‚’æƒ³å®šï¼‰"""
    try:
        df = pd.read_csv(CSV_FILE)
        # æœ€ä½é™ã®åˆ—ãƒã‚§ãƒƒã‚¯
        required = {"å¹´", "æœˆ", "URL"}
        if not required.issubset(df.columns):
            st.error(f"{CSV_FILE} ã«å¿…è¦ãªåˆ—ï¼ˆå¹´, æœˆ, URLï¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return pd.DataFrame()
        return df
    except Exception as e:
        logger.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        st.error("ãƒ‡ãƒ¼ã‚¿URLã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return pd.DataFrame()


def load_history_data() -> pd.DataFrame:
    """éå»ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆç„¡ã‘ã‚Œã°ç©ºDataFrameï¼‰"""
    try:
        df = pd.read_csv(HISTORY_CSV_FILE)
        if df.empty:
            return pd.DataFrame(columns=HISTORY_REQUIRED_COLS)

        # å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯
        missing_cols = [c for c in HISTORY_REQUIRED_COLS if c not in df.columns]
        if missing_cols:
            logger.warning(f"å±¥æ­´CSVã«å¿…è¦åˆ—ãŒä¸è¶³: {missing_cols}")
            return pd.DataFrame(columns=HISTORY_REQUIRED_COLS)

        # å‹ã‚’å®‰å…¨ã«æ•´ãˆã‚‹ï¼ˆå£Šã‚ŒãŸå€¤ãŒã‚ã£ã¦ã‚‚è½ã¡ã«ããï¼‰
        df["year"] = pd.to_numeric(df["year"], errors="coerce").astype("Int64")
        df["month"] = pd.to_numeric(df["month"], errors="coerce").astype("Int64")
        df["day"] = pd.to_numeric(df["day"], errors="coerce").astype("Int64")

        # year/month/day ãŒæ¬ æã®è¡Œã¯æ¨ã¦ã‚‹
        df = df.dropna(subset=["year", "month", "day"]).copy()
        df["year"] = df["year"].astype(int)
        df["month"] = df["month"].astype(int)
        df["day"] = df["day"].astype(int)

        # location ã¯æ–‡å­—åˆ—ã§çµ±ä¸€
        df["location"] = df["location"].astype(str)

        return df

    except FileNotFoundError:
        logger.info("éå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
        return pd.DataFrame(columns=HISTORY_REQUIRED_COLS)
    except Exception as e:
        logger.error(f"éå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        return pd.DataFrame(columns=HISTORY_REQUIRED_COLS)


def save_history_data(df: pd.DataFrame) -> None:
    """éå»ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹"""
    try:
        # åˆ—é †ã‚’æƒãˆã‚‹ï¼ˆèª­è€…ãŒè¦‹ã¦ã‚‚åˆ†ã‹ã‚Šã‚„ã™ã„ï¼‰
        df = df.reindex(columns=HISTORY_REQUIRED_COLS)
        df.to_csv(HISTORY_CSV_FILE, index=False)
        logger.info(f"éå»ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {len(df)}ä»¶")
    except Exception as e:
        logger.error(f"éå»ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã«å¤±æ•—: {e}")


# ==========
# æœ€æ–°å…¬é–‹æœˆï¼ˆURLä¸€è¦§ãƒ™ãƒ¼ã‚¹ï¼‰
# ==========
def get_latest_available_month(url_df: pd.DataFrame) -> Tuple[int, int]:
    """URLä¸€è¦§ã‹ã‚‰ã€æœ€æ–°ã®ï¼ˆå¹´,æœˆï¼‰ã‚’è¿”ã™"""
    if url_df.empty:
        now = datetime.now()
        return now.year, now.month

    sorted_df = url_df.sort_values(["å¹´", "æœˆ"], ascending=False)
    latest = sorted_df.iloc[0]
    return int(latest["å¹´"]), int(latest["æœˆ"])


def is_latest_month(year: int, month: int, latest_year: int, latest_month: int) -> bool:
    """æŒ‡å®šå¹´æœˆãŒã€URLä¸€è¦§ã«ãŠã‘ã‚‹æœ€æ–°å…¬é–‹æœˆã‹ã©ã†ã‹"""
    return year == latest_year and month == latest_month


# ==========
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
# ==========
def _pick_data_table(soup: BeautifulSoup) -> Optional[BeautifulSoup]:
    """
    å¦™é«˜å¸‚ãƒšãƒ¼ã‚¸å†…ã® tables ã‹ã‚‰ã€è¦³æ¸¬æ‰€åãŒå«ã¾ã‚Œã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å„ªå…ˆã—ã¦é¸ã¶ã€‚
    è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°æœ€åˆã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¿”ã™ã€‚
    """
    tables = soup.find_all("table")
    if not tables:
        return None

    # è¦³æ¸¬æ‰€åãŒå«ã¾ã‚Œã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å„ªå…ˆ
    for tbl in tables:
        text = tbl.get_text(" ", strip=True)
        if all(loc in text for loc in LOCATIONS):
            return tbl

    return tables[0]


def _to_float_or_none(s: str) -> Optional[float]:
    """
    æ•°å€¤ã£ã½ã„æ–‡å­—åˆ—ã‚’floatã«ã€‚ "-", "--", "" ã¯ Noneã€‚
    "30-" ã®ã‚ˆã†ãªæœ«å°¾ '-' ã¯é™¤å»ã€‚
    """
    x = (s or "").strip()
    if x in {"-", "--", ""}:
        return None
    x = x.rstrip("-").strip()
    if x == "":
        return None
    try:
        return float(x)
    except ValueError:
        return None


@st.cache_data(ttl=3600)
def fetch_snow_data(url: str, year: int, month: int) -> Optional[pd.DataFrame]:
    """æŒ‡å®šURLã‹ã‚‰é™é›ªãƒ»ç©é›ªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ tidy DataFrame ã‚’è¿”ã™ï¼ˆå¤±æ•—æ™‚Noneï¼‰"""
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        response.encoding = response.apparent_encoding

        soup = BeautifulSoup(response.text, "lxml")

        table = _pick_data_table(soup)
        if table is None:
            logger.warning(f"ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {url}")
            return None

        rows = table.find_all("tr")
        if len(rows) < 3:
            logger.warning(f"ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œæ•°ãŒå°‘ãªã™ãã¾ã™: {url}")
            return None

        data_rows = []

        # ãƒ˜ãƒƒãƒ€ãƒ¼ã¯åŸºæœ¬2è¡Œæƒ³å®šã€‚ãŸã ã—å£Šã‚Œã«ãã„ã‚ˆã†ã€æ—¥ä»˜åˆ—ãŒå–ã‚ŒãŸè¡Œã ã‘æ¡ç”¨ã™ã‚‹
        for row in rows[1:]:
            cols = row.find_all(["td", "th"])
            if len(cols) < 7:
                continue

            cols_text = [c.get_text(strip=True) for c in cols]

            # 1åˆ—ç›®ã‹ã‚‰æ—¥ä»˜ã‚’å–ã‚‹ï¼ˆä¾‹: "3æ—¥"ï¼‰
            day_text = cols_text[0].replace("æ—¥", "").strip()
            if not day_text.isdigit():
                continue
            day = int(day_text)

            # å®Ÿéš›ã®åˆ—é †: [æ—¥, é™é›ª1, ç©é›ª1, é™é›ª2, ç©é›ª2, é™é›ª3, ç©é›ª3]
            for i, location in enumerate(LOCATIONS):
                snowfall_idx = i * 2 + 1
                snowdepth_idx = i * 2 + 2

                snowfall_raw = cols_text[snowfall_idx] if snowfall_idx < len(cols_text) else "-"
                snowdepth_raw = cols_text[snowdepth_idx] if snowdepth_idx < len(cols_text) else "-"

                snowfall_cm = _to_float_or_none(snowfall_raw)
                snowdepth_cm = _to_float_or_none(snowdepth_raw)

                # ç©é›ªé‡ãŒè² ã«ãªã‚‹ã®ã¯ä»•æ§˜çš„ã«ãŠã‹ã—ã„ã®ã§ None æ‰±ã„
                if snowdepth_cm is not None and snowdepth_cm < 0:
                    snowdepth_cm = None

                data_rows.append(
                    {
                        "year": year,
                        "month": month,
                        "day": day,
                        "location": location,
                        "snowfall_cm": snowfall_cm,
                        "snowdepth_cm": snowdepth_cm,
                    }
                )

        if not data_rows:
            logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ: {url}")
            return None

        return pd.DataFrame(data_rows)

    except requests.RequestException as e:
        logger.error(f"HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {url} - {e}")
        return None
    except Exception as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {url} - {e}")
        return None


# ==========
# ãƒ‡ãƒ¼ã‚¿å–å¾—æˆ¦ç•¥ï¼ˆåˆ†å²ãƒ­ã‚¸ãƒƒã‚¯ã‚’é›†ç´„ï¼‰
# ==========
def history_has_month(history_df: pd.DataFrame, year: int, month: int) -> bool:
    if history_df.empty:
        return False
    return not history_df[(history_df["year"] == year) & (history_df["month"] == month)].empty


def get_month_df(
    *,
    year: int,
    month: int,
    url: str,
    location: str,
    history_df: pd.DataFrame,
    latest_year: int,
    latest_month: int,
) -> Tuple[Optional[pd.DataFrame], pd.DataFrame, bool]:
    """
    æŒ‡å®šå¹´æœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™ã€‚
    - æœ€æ–°å…¬é–‹æœˆ: æ¯å›Webå–å¾—ï¼ˆæ›´æ–°ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
    - ãã‚Œä»¥å¤–: å±¥æ­´CSVã‹ã‚‰ï¼ˆç„¡ã‘ã‚Œã°Webå–å¾—ã—ã¦å±¥æ­´ã«è¿½è¨˜ï¼‰
    æˆ»ã‚Šå€¤:
      (df, updated_history_df, history_updated_flag)
    """
    history_updated = False

    if is_latest_month(year, month, latest_year, latest_month):
        # æœ€æ–°å…¬é–‹æœˆã¯æ¯å›å–å¾—
        df = fetch_snow_data(url, year, month)
        return df, history_df, False

    # éå»æœˆï¼šå±¥æ­´ã«ã‚ã‚Œã°ãã‚Œã‚’ä½¿ã†
    if history_has_month(history_df, year, month):
        df = history_df[(history_df["year"] == year) & (history_df["month"] == month)].copy()
        return df, history_df, False

    # å±¥æ­´ã«ãªã„ â†’ Webå–å¾—ã—ã¦å±¥æ­´ã«è¿½è¨˜
    df = fetch_snow_data(url, year, month)
    if df is not None and not df.empty:
        if history_df.empty:
            history_df = df.copy()
        else:
            history_df = pd.concat([history_df, df], ignore_index=True)
        history_updated = True

    return df, history_df, history_updated


# ==========
# ã‚°ãƒ©ãƒ•
# ==========
def create_snow_graph(df: pd.DataFrame, year: int, month: int, location: str) -> go.Figure:
    """é™é›ªãƒ»ç©é›ªã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
    filtered_df = df[
        (df["year"] == year) & (df["month"] == month) & (df["location"] == location)
    ].sort_values("day")

    fig = make_subplots(specs=[[{"secondary_y": True}]])

    # ç©é›ªé‡ï¼ˆæ£’ï¼‰: å·¦
    fig.add_trace(
        go.Bar(
            x=filtered_df["day"],
            y=filtered_df["snowdepth_cm"],
            name="ç©é›ªé‡",
            opacity=0.7,
        ),
        secondary_y=False,
    )

    # é™é›ªé‡ï¼ˆç·šï¼‰: å³
    fig.add_trace(
        go.Scatter(
            x=filtered_df["day"],
            y=filtered_df["snowfall_cm"],
            name="é™é›ªé‡",
            mode="lines+markers",
            line=dict(color="red"),
            marker=dict(color="red"),
        ),
        secondary_y=True,
    )

    fig.update_layout(
        title=f"{year}å¹´{month}æœˆ / {location}",
        xaxis_title="æ—¥",
        hovermode="x unified",
        height=400,
        showlegend=True,
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
    )

    fig.update_xaxes(range=[0.5, 31.5], dtick=5)

    fig.update_yaxes(
        title_text="ç©é›ªé‡ (cm)",
        range=[0, 300],
        dtick=60,
        secondary_y=False,
    )
    fig.update_yaxes(
        title_text="é™é›ªé‡ (cm)",
        range=[0, 100],
        dtick=20,
        secondary_y=True,
    )

    return fig


# ==========
# ãƒ¡ã‚¤ãƒ³
# ==========
def main() -> None:
    st.set_page_config(page_title="å¦™é«˜å¸‚ é™é›ªãƒ»ç©é›ªãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–", page_icon="â„ï¸", layout="wide")

    st.title("â„ï¸ å¦™é«˜å¸‚ é™é›ªãƒ»ç©é›ªãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–")
    st.markdown("---")

    url_df = load_url_data()
    if url_df.empty:
        st.error("ãƒ‡ãƒ¼ã‚¿URLãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã€‚data_urls.csv ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    latest_year, latest_month = get_latest_available_month(url_df)

    # åˆ©ç”¨å¯èƒ½ãªå¹´
    available_years = sorted(url_df["å¹´"].unique())

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.header("ğŸ“Š è¡¨ç¤ºæ¡ä»¶è¨­å®š")
    st.sidebar.markdown("æœ€å¤§3ä»¶ã¾ã§é¸æŠã§ãã¾ã™")

    selections = []
    for i in range(3):
        st.sidebar.markdown(f"### æ¡ä»¶ {i + 1}")
        col1, col2 = st.sidebar.columns(2)

        with col1:
            default_year_idx = available_years.index(latest_year) if latest_year in available_years else 0
            year = st.selectbox("å¹´", options=available_years, index=default_year_idx, key=f"year_{i}")

        with col2:
            available_months = sorted(url_df[url_df["å¹´"] == year]["æœˆ"].unique())
            default_month_idx = available_months.index(latest_month) if latest_month in available_months else 0
            month = st.selectbox("æœˆ", options=available_months, index=default_month_idx, key=f"month_{i}")

        default_location_idx = i if i < len(LOCATIONS) else 0
        location = st.sidebar.selectbox(
            "è¦³æ¸¬åœ°ç‚¹", options=LOCATIONS, index=default_location_idx, key=f"location_{i}"
        )

        selections.append({"year": year, "month": month, "location": location})
        st.sidebar.markdown("---")

    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    unique_selections = []
    seen = set()
    for sel in selections:
        key = (sel["year"], sel["month"], sel["location"])
        if key in seen:
            st.sidebar.warning(f"âš ï¸ {sel['year']}å¹´{sel['month']}æœˆ / {sel['location']} ãŒé‡è¤‡ã—ã¦ã„ã¾ã™")
            continue
        seen.add(key)
        unique_selections.append(sel)

    # å±¥æ­´èª­ã¿è¾¼ã¿
    history_df = load_history_data()

    st.markdown("## ğŸ“ˆ ã‚°ãƒ©ãƒ•è¡¨ç¤º")

    # è¡¨ç¤ºã”ã¨ã«å–å¾—ï¼ˆå¿…è¦ãªã‚‰å±¥æ­´æ›´æ–°ï¼‰
    history_updated_any = False

    for sel in unique_selections:
        year = int(sel["year"])
        month = int(sel["month"])
        location = sel["location"]

        url_row = url_df[(url_df["å¹´"] == year) & (url_df["æœˆ"] == month)]
        if url_row.empty:
            st.warning(f"âš ï¸ {year}å¹´{month}æœˆã®ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“")
            continue

        url = url_row.iloc[0]["URL"]

        with st.spinner(f"{year}å¹´{month}æœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­..."):
            df, history_df, history_updated = get_month_df(
                year=year,
                month=month,
                url=url,
                location=location,
                history_df=history_df,
                latest_year=latest_year,
                latest_month=latest_month,
            )
            if history_updated:
                history_updated_any = True

        if df is None or df.empty:
            st.error(f"âŒ {year}å¹´{month}æœˆ / {location} ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            continue

        fig = create_snow_graph(df, year, month, location)
        st.plotly_chart(fig, use_container_width=True)

    # å±¥æ­´ãŒæ›´æ–°ã•ã‚ŒãŸã‚‰ä¿å­˜ï¼ˆæœ€å¾Œã«ã¾ã¨ã‚ã¦1å›ï¼‰
    if history_updated_any:
        save_history_data(history_df)

    st.markdown("---")
    st.markdown(
        """
    <div style='text-align: center; color: #888; font-size: 0.9em;'>
        ãƒ‡ãƒ¼ã‚¿å‡ºå…¸: <a href='https://www.city.myoko.niigata.jp/life-info/snow-info/snow/' target='_blank'>å¦™é«˜å¸‚ é›ªæƒ…å ±ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸</a><br>
        è¦³æ¸¬æ™‚åˆ»: 9æ™‚ | é™é›ªé‡: å‰æ—¥åˆ† | ç©é›ªé‡: å½“æ—¥åˆ†
    </div>
    """,
        unsafe_allow_html=True,
    )


if __name__ == "__main__":
    main()
